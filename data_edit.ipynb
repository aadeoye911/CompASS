{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from data_loading import scan_folders, create_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "\n",
    "def update_file_paths_in_csv(csv_file, base_folder, composition_categories, frame_size_categories):\n",
    "    \"\"\"Update the file paths in the existing CSV.\"\"\"\n",
    "    # Load the existing CSV into a DataFrame\n",
    "    df = pd.read_csv(csv_file)\n",
    "    image_data = scan_folders(base_folder, composition_categories, frame_size_categories)\n",
    "    \n",
    "    # Initialize a list to collect updated rows\n",
    "    updated_rows = []\n",
    "\n",
    "    # Update existing images by checking for valid file paths and updating metadata\n",
    "    for idx, row in df.iterrows():\n",
    "        img_hash = row['Image Hash']\n",
    "        if img_hash in image_data:\n",
    "            # Only keep file paths that exist\n",
    "            valid_paths = [path for path in image_data[img_hash][\"file_paths\"] if os.path.exists(path)]\n",
    "            df.at[idx, \"File Paths\"] = \", \".join(valid_paths)  # Update the file paths column\n",
    "\n",
    "            # Update the composition and frame size\n",
    "            df.at[idx, \"Composition\"] = \", \".join(image_data[img_hash][\"composition\"]) if image_data[img_hash][\"composition\"] else \"Unknown\"\n",
    "            df.at[idx, \"Frame Size\"] = \", \".join(image_data[img_hash][\"frame_size\"]) if image_data[img_hash][\"frame_size\"] else \"Unknown\"\n",
    "    \n",
    "    # Handle new images (those not in the original DataFrame)\n",
    "    existing_hashes = set(df['Image Hash'])\n",
    "    for img_hash, metadata in image_data.items():\n",
    "        if img_hash not in existing_hashes:\n",
    "            # Add new row for this image\n",
    "            new_row = {\n",
    "                'Image Hash': img_hash,\n",
    "                'Composition': \", \".join(metadata[\"composition\"]) if metadata[\"composition\"] else \"Unknown\",\n",
    "                'Frame Size': \", \".join(metadata[\"frame_size\"]) if metadata[\"frame_size\"] else \"Unknown\",\n",
    "                'File Paths': \", \".join(metadata[\"file_paths\"]),\n",
    "                'Width': metadata[\"width\"],\n",
    "                'Height': metadata[\"height\"],\n",
    "                'Aspect Ratio': round(metadata[\"width\"] / metadata[\"height\"], 2) if metadata[\"width\"] and metadata[\"height\"] else None\n",
    "            }\n",
    "            df = df.append(new_row, ignore_index=True)\n",
    "\n",
    "    # Save the updated DataFrame back to CSV\n",
    "    df.to_csv(\"shotdeck_update.csv\", index=False)\n",
    "    print(f\"DataFrame updated and saved to shotdeck_update.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "composition_categories = [\"balanced\", \"center\", \"left\", \"right\", \"symmetrical\"]\n",
    "frame_size_categories = [\"ECU\", \"CU\", \"MCU\", \"MS\", \"MWS\", \"WS\", \"EWS\"]\n",
    "\n",
    "base_folder = \"shotdeck_data\"  # Root folder containing subfolders for composition and frame size\n",
    "csv_file = \"shotdeck_v2.csv\"  # Existing CSV file to update\n",
    "\n",
    "# Update file paths in the CSV and remove non-existing file paths\n",
    "update_file_paths_in_csv(csv_file, base_folder, composition_categories, frame_size_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_attention_maps(hdf5_path, layer_key):\n",
    "    with h5py.File(hdf5_path, \"r\") as f:\n",
    "        data = []\n",
    "        \n",
    "        # Loop through each image group\n",
    "        for image_hash in f.keys():\n",
    "            row_data = {\"image_hash\": image_hash}\n",
    "\n",
    "            # Loop through all layers for this image\n",
    "            for layer_key in f[image_hash].keys():\n",
    "                row_data[layer_key] = f[image_hash][layer_key][:]  # Convert back to PyTorch Tensor\n",
    "\n",
    "            data.append(row_data)\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load the attention maps into a DataFrame\n",
    "hdf5_path = \"shotdeck_attention_maps.h5\"\n",
    "df_attn_maps = load_attention_maps(hdf5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display DataFrame\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Loaded Attention Maps\", dataframe=df_attn_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"shotdeck_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Image Hash Composition Frame Size  \\\n",
      "632   5da5f45bfd6296ac4ad77ae64e309d17     Unknown         MS   \n",
      "653   5c1c8139d61889d2eafc1e6718b720ce     Unknown         MS   \n",
      "667   e156acee9fef60f186ce592c890c37df     Unknown         MS   \n",
      "754   7d8ae5d26f0bafe090b493433cd2cc07     Unknown         MS   \n",
      "775   e5c2ca9229afd82e4f3d3c529a4cb54d     Unknown    MS, MWS   \n",
      "...                                ...         ...        ...   \n",
      "4470  e1b2ee1de174a120cab016aca4454b07     Unknown         WS   \n",
      "4471  1f42441fd95bc2ab2160a64cd2fa642e     Unknown         WS   \n",
      "4472  33a3b677429be2e5b34fd58edc1a49f6     Unknown         WS   \n",
      "4473  ce0fe54186b23b6c005e0c777f9aadd4     Unknown         WS   \n",
      "4474  7309d3cbdadd5b9ce5b38acc9e5bb4d6     Unknown         WS   \n",
      "\n",
      "                                             File Paths  Width  Height  \\\n",
      "632   ['shotdeck_data/MS/63 - The Royal Tenenbaums.j...   1920     800   \n",
      "653                ['shotdeck_data/MS/55 - Minari.jpg']   1920     802   \n",
      "667   ['shotdeck_data/MS/384 - Once Upon a Time in H...   1920     800   \n",
      "754             ['shotdeck_data/MS/14 - The Rider.jpg']   1920     801   \n",
      "775   ['shotdeck_data/MS/211 - Pineapple Express.jpg...   1920     805   \n",
      "...                                                 ...    ...     ...   \n",
      "4470      ['shotdeck_data/WS/278 - Jennifers Body.jpg']   1920    1035   \n",
      "4471          ['shotdeck_data/WS/537 - The Square.jpg']   1920    1038   \n",
      "4472                ['shotdeck_data/WS/471 - Rent.png']   1920     799   \n",
      "4473           ['shotdeck_data/WS/476 - To Leslie.jpg']   1920     801   \n",
      "4474            ['shotdeck_data/WS/426 - Aftersun.jpg']   1924    1040   \n",
      "\n",
      "      Aspect Ratio  \n",
      "632           2.40  \n",
      "653           2.39  \n",
      "667           2.40  \n",
      "754           2.40  \n",
      "775           2.39  \n",
      "...            ...  \n",
      "4470          1.86  \n",
      "4471          1.85  \n",
      "4472          2.40  \n",
      "4473          2.40  \n",
      "4474          1.85  \n",
      "\n",
      "[610 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df[df[\"Frame Size\"].str.split(\", \").str.len() == 3]\n",
    "# Print all first file names from the File Paths column\n",
    "# Ensure File Paths column contains lists, then extract first file name from each list\n",
    "\n",
    "\n",
    "# Convert File Paths column from string to list\n",
    "df_unknown = df[(df[\"Composition\"] == \"Unknown\") | (df[\"Frame Size\"] == \"Unknown\")]\n",
    "\n",
    "# Print results\n",
    "print(df_unknown)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unknown.to_csv(\"missing_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
