{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import hashlib\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from PIL import Image\n",
    "from data_loading import scan_folders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Image Hash Composition Frame Size  \\\n",
      "632  5da5f45bfd6296ac4ad77ae64e309d17     Unknown         MS   \n",
      "653  5c1c8139d61889d2eafc1e6718b720ce     Unknown        MWS   \n",
      "667  e156acee9fef60f186ce592c890c37df     Unknown         MS   \n",
      "754  7d8ae5d26f0bafe090b493433cd2cc07     Unknown         MS   \n",
      "775  e5c2ca9229afd82e4f3d3c529a4cb54d     Unknown    MS, MWS   \n",
      "\n",
      "                                            File Paths  Width  Height  \\\n",
      "632     shotdeck_data/MS/61 - The Royal Tenenbaums.jpg   1920     800   \n",
      "653                 shotdeck_data/MWS/599 - Minari.jpg   1920     802   \n",
      "667  shotdeck_data/MS/382 - Once Upon a Time in Hol...   1920     800   \n",
      "754                shotdeck_data/MS/13 - The Rider.jpg   1920     801   \n",
      "775  shotdeck_data/MS/209 - Pineapple Express.jpg, ...   1920     805   \n",
      "\n",
      "     Aspect Ratio                                       Resized Path  \\\n",
      "632          2.40  shotdeck_resized/5da5f45bfd6296ac4ad77ae64e309...   \n",
      "653          2.39  shotdeck_resized/5c1c8139d61889d2eafc1e6718b72...   \n",
      "667          2.40  shotdeck_resized/e156acee9fef60f186ce592c890c3...   \n",
      "754          2.40  shotdeck_resized/7d8ae5d26f0bafe090b493433cd2c...   \n",
      "775          2.39  shotdeck_resized/e5c2ca9229afd82e4f3d3c529a4cb...   \n",
      "\n",
      "     Resized Width  Resized Height  Resized Aspect Ratio  \n",
      "632           1216             512                  2.38  \n",
      "653           1216             512                  2.38  \n",
      "667           1216             512                  2.38  \n",
      "754           1216             512                  2.38  \n",
      "775           1216             512                  2.38  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"shotdeck_update.csv\")\n",
    "# df_filtered = df[df[\"Frame Size\"].str.split(\", \").str.len() == 2]\n",
    "# print(df_filtered)\n",
    "# # Print all first file names from the File Paths column\n",
    "\n",
    "# # Convert File Paths column from string to list\n",
    "df_unknown = df[(df[\"Composition\"] == \"Unknown\")]\n",
    "\n",
    "# # Print results\n",
    "print(df_unknown.head())\n",
    "df_unknown.to_csv(\"missing_comp.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def load_attention_maps(hdf5_path, layer_key):\n",
    "    with h5py.File(hdf5_path, \"r\") as f:\n",
    "        data = []\n",
    "        \n",
    "        # Loop through each image group\n",
    "        for image_hash in f.keys():\n",
    "            row_data = {\"image_hash\": image_hash}\n",
    "\n",
    "            # Loop through all layers for this image\n",
    "            for layer_key in f[image_hash].keys():\n",
    "                row_data[layer_key] = f[image_hash][layer_key][:]  # Convert back to PyTorch Tensor\n",
    "\n",
    "            data.append(row_data)\n",
    "\n",
    "    return pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Load the attention maps into a DataFrame\n",
    "hdf5_path = \"shotdeck_attention_maps.h5\"\n",
    "df_attn_maps = load_attention_maps(hdf5_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display DataFrame\n",
    "import ace_tools as tools\n",
    "tools.display_dataframe_to_user(name=\"Loaded Attention Maps\", dataframe=df_attn_maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"shotdeck_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():    # Predict the noise at this timestep    noise_pred = pipe.unet(noisy_latents, timesteps, pipe.text_encoder.encode(\"A futuristic city\")).sample    # Compute denoised latents    denoised_latents = pipe.scheduler.step(noise_pred, timesteps, noisy_latents).prev_sample    # Decode to an image    \n",
    "    image = pipe.vae.decode(denoised_latents / pipe.vae.config.scaling_factor).sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(960, 512)\n",
      "(960, 512)\n",
      "torch.Size([1, 3, 512, 960])\n"
     ]
    }
   ],
   "source": [
    "image = Image.open(\"shotdeck_resized/0a3d5713428664522bd168d5a9788b1b.png\")\n",
    "print(image.size)\n",
    "image = resize_image(image)\n",
    "print(image.size)\n",
    "transform = Compose([ToTensor(), Normalize([0.5], [0.5])])\n",
    "image_tensor = transform(image).unsqueeze(0)\n",
    "print(image_tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'height' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 8\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdata\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Passing an empty variable\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[43mheight\u001b[49m\n\u001b[1;32m      9\u001b[0m my_function(height)  \u001b[38;5;66;03m# Output: Received: []\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'height' is not defined"
     ]
    }
   ],
   "source": [
    "def my_function(data=None):\n",
    "    if data is None:\n",
    "        print(\"No input provided (defaulting to None).\")\n",
    "    else:\n",
    "        print(f\"Received: {data}\")\n",
    "\n",
    "# Passing an empty variable\n",
    "height\n",
    "my_function(height)  # Output: Received: []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            Image Hash Composition Frame Size  \\\n",
      "632   5da5f45bfd6296ac4ad77ae64e309d17     Unknown         MS   \n",
      "653   5c1c8139d61889d2eafc1e6718b720ce     Unknown         MS   \n",
      "667   e156acee9fef60f186ce592c890c37df     Unknown         MS   \n",
      "754   7d8ae5d26f0bafe090b493433cd2cc07     Unknown         MS   \n",
      "775   e5c2ca9229afd82e4f3d3c529a4cb54d     Unknown    MS, MWS   \n",
      "...                                ...         ...        ...   \n",
      "4470  e1b2ee1de174a120cab016aca4454b07     Unknown         WS   \n",
      "4471  1f42441fd95bc2ab2160a64cd2fa642e     Unknown         WS   \n",
      "4472  33a3b677429be2e5b34fd58edc1a49f6     Unknown         WS   \n",
      "4473  ce0fe54186b23b6c005e0c777f9aadd4     Unknown         WS   \n",
      "4474  7309d3cbdadd5b9ce5b38acc9e5bb4d6     Unknown         WS   \n",
      "\n",
      "                                             File Paths  Width  Height  \\\n",
      "632   ['shotdeck_data/MS/63 - The Royal Tenenbaums.j...   1920     800   \n",
      "653                ['shotdeck_data/MS/55 - Minari.jpg']   1920     802   \n",
      "667   ['shotdeck_data/MS/384 - Once Upon a Time in H...   1920     800   \n",
      "754             ['shotdeck_data/MS/14 - The Rider.jpg']   1920     801   \n",
      "775   ['shotdeck_data/MS/211 - Pineapple Express.jpg...   1920     805   \n",
      "...                                                 ...    ...     ...   \n",
      "4470      ['shotdeck_data/WS/278 - Jennifers Body.jpg']   1920    1035   \n",
      "4471          ['shotdeck_data/WS/537 - The Square.jpg']   1920    1038   \n",
      "4472                ['shotdeck_data/WS/471 - Rent.png']   1920     799   \n",
      "4473           ['shotdeck_data/WS/476 - To Leslie.jpg']   1920     801   \n",
      "4474            ['shotdeck_data/WS/426 - Aftersun.jpg']   1924    1040   \n",
      "\n",
      "      Aspect Ratio  \n",
      "632           2.40  \n",
      "653           2.39  \n",
      "667           2.40  \n",
      "754           2.40  \n",
      "775           2.39  \n",
      "...            ...  \n",
      "4470          1.86  \n",
      "4471          1.85  \n",
      "4472          2.40  \n",
      "4473          2.40  \n",
      "4474          1.85  \n",
      "\n",
      "[610 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df_filtered = df[df[\"Frame Size\"].str.split(\", \").str.len() == 3]\n",
    "# Print all first file names from the File Paths column\n",
    "# Ensure File Paths column contains lists, then extract first file name from each list\n",
    "\n",
    "\n",
    "# Convert File Paths column from string to list\n",
    "df_unknown = df[(df[\"Composition\"] == \"Unknown\") | (df[\"Frame Size\"] == \"Unknown\")]\n",
    "\n",
    "# Print results\n",
    "print(df_unknown)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unknown.to_csv(\"missing_labels.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
